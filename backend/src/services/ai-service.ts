import dotenv from "dotenv";
dotenv.config();

import OpenAI from "openai";
import Groq from "groq-sdk";
import { MyContext } from "../types";
import { ChatCompletionMessageParam as OpenAIMessage } from "openai/resources/chat";
import { ChatCompletionMessageParam as GroqMessage } from "groq-sdk/resources/chat/completions";
import { loadKnowledgeBase, findAnswerInKB } from "../utils/knowledgeBase";
import { systemPrompt } from "../prompts/systemPrompt";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const deepseek = new OpenAI({
  apiKey: process.env.DEEPSEEK_API_KEY,
  baseURL: "https://api.deepseek.com",
});

const groq = new Groq({
  apiKey: process.env.GROQ_API_KEY,
});

export async function getAIResponse(
  ctx: MyContext,
  prompt: string,
  context = ""
): Promise<string> {
  ctx.session.chatHistory ||= [];

  // –°–Ω–∞—á–∞–ª–∞ –≤—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
  let kbAnswer: string | null = null;
  let isPotentialServiceName = false;
  console.log("üîç –ü—Ä–æ–≤–µ—Ä—è—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –ø–æ prompt:", prompt);
  try {
    const kb = await loadKnowledgeBase();
    kbAnswer = findAnswerInKB(kb, prompt);

    const normalizedPrompt = prompt.toLowerCase().trim();
    isPotentialServiceName = kb?.some(
      (entry) =>
        entry.short.toLowerCase().trim() === normalizedPrompt &&
        !entry.answer.toLowerCase().includes("—Ü–µ–Ω")
    );
    // –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –±–∞–∑–µ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ
    if (kbAnswer) {
      ctx.session.chatHistory.push(
        { role: "user", content: prompt, timestamp: new Date() },
        { role: "assistant", content: kbAnswer, timestamp: new Date() }
      );
      ctx.session.chatHistory = ctx.session.chatHistory.slice(-10);
      console.log("üìö –û—Ç–≤–µ—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:", kbAnswer);
      return kbAnswer;
    }
  } catch (err) {
    console.warn(
      "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π:",
      (err as Error).message
    );
  }

  // –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤ –±–∞–∑–µ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ - –ø—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
  const pricingKeywords = [
    "—Ü–µ–Ω–∞",
    "—Å—Ç–æ–∏–º–æ—Å—Ç—å",
    "—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç",
    "–ø–æ —á–µ–º",
    "—Ä–∞—Å—Ü–µ–Ω–∫–∞",
    "–ø—Ä–∞–π—Å",
    "—Å–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç",
  ];

  const isPriceRelated = pricingKeywords.some((kw) =>
    prompt.toLowerCase().includes(kw)
  );

  if (isPriceRelated) {
    return "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –º–æ–≥—É —Ç–æ—á–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏. –õ—É—á—à–µ —É—Ç–æ—á–Ω–∏—Ç—å —É –Ω–∞—à–µ–≥–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞.";
  }

  const openaiMessages: OpenAIMessage[] = [
    { role: "system", content: systemPrompt + "\n" + context },
    ...ctx.session.chatHistory.map((m) => ({
      role: m.role as "user" | "assistant",
      content: m.content,
    })),
    { role: "user", content: prompt },
  ];

  const groqMessages: GroqMessage[] = [
    { role: "system", content: systemPrompt + "\n" + context },
    ...ctx.session.chatHistory.map((m) => ({
      role: m.role as "user" | "assistant",
      content: m.content,
    })),
    { role: "user", content: prompt },
  ];

  async function tryOpenAICompletion(client: OpenAI, model: string) {
    const res = await client.chat.completions.create({
      model,
      messages: openaiMessages,
      temperature: 0.7,
    });
    if (res.choices.length === 0) throw new Error("No response from AI");
    return res.choices[0].message?.content ?? "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç";
  }

  async function tryGroqCompletion() {
    const res = await groq.chat.completions.create({
      model: "llama-3.3-70b-versatile",
      messages: groqMessages,
    });
    if (!res.choices || res.choices.length === 0)
      throw new Error("No response from Groq AI");
    return (
      res.choices[0].message?.content || "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç Groq"
    );
  }

  try {
    const response = await tryOpenAICompletion(openai, "gpt-3.5-turbo");

    ctx.session.chatHistory.push(
      { role: "user", content: prompt, timestamp: new Date() },
      { role: "assistant", content: response, timestamp: new Date() }
    );
    ctx.session.chatHistory = ctx.session.chatHistory.slice(-10);

    return response;
  } catch (errOpenAI) {
    console.log(
      "OpenAI error, fallback to DeepSeek:",
      (errOpenAI as Error).message
    );

    try {
      const response = await tryOpenAICompletion(deepseek, "deepseek-chat");

      ctx.session.chatHistory.push(
        { role: "user", content: prompt, timestamp: new Date() },
        { role: "assistant", content: response, timestamp: new Date() }
      );
      ctx.session.chatHistory = ctx.session.chatHistory.slice(-10);

      return response;
    } catch (errDeepSeek) {
      console.log(
        "DeepSeek error, fallback to Groq:",
        (errDeepSeek as Error).message
      );

      try {
        const response = await tryGroqCompletion();

        ctx.session.chatHistory.push(
          { role: "user", content: prompt, timestamp: new Date() },
          { role: "assistant", content: response, timestamp: new Date() }
        );
        ctx.session.chatHistory = ctx.session.chatHistory.slice(-10);

        return response;
      } catch (errGroq) {
        console.error("Groq error:", (errGroq as Error).message);
        throw new Error("–í—Å–µ AI-—Å–µ—Ä–≤–∏—Å—ã –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.");
      }
    }
  }
}
